{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "ai_JU12KRBR-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4ba1617-b6da-4d20-d5c6-de8918a99eb4"
      },
      "id": "ai_JU12KRBR-",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat 'kaggle.json': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVG--uEnSc3Q",
        "outputId": "1831f47f-d48b-4ce4-caf7-ae08cef1d28c"
      },
      "id": "IVG--uEnSc3Q",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.10.5)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle kernels output datam0nstr/toxic-comment-classification -p /content/toxic_output\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgvgQSCOSjT9",
        "outputId": "49b96ae6-7feb-4121-9f22-bf13e2e24641"
      },
      "id": "TgvgQSCOSjT9",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "added_tokens.json: Skipping, found more recently modified local copy (use --force to force download)\n",
            "config.json: Skipping, found more recently modified local copy (use --force to force download)\n",
            "model.safetensors: Skipping, found more recently modified local copy (use --force to force download)\n",
            "special_tokens_map.json: Skipping, found more recently modified local copy (use --force to force download)\n",
            "spm.model: Skipping, found more recently modified local copy (use --force to force download)\n",
            "tokenizer.json: Skipping, found more recently modified local copy (use --force to force download)\n",
            "tokenizer_config.json: Skipping, found more recently modified local copy (use --force to force download)\n",
            "submission.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Kernel log downloaded to /content/toxic_output/toxic-comment-classification.log \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f0e28af5",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-10-22T09:44:34.874130Z",
          "iopub.status.busy": "2025-10-22T09:44:34.873620Z",
          "iopub.status.idle": "2025-10-22T09:44:36.139478Z",
          "shell.execute_reply": "2025-10-22T09:44:36.138760Z"
        },
        "papermill": {
          "duration": 1.27205,
          "end_time": "2025-10-22T09:44:36.140944",
          "exception": false,
          "start_time": "2025-10-22T09:44:34.868894",
          "status": "completed"
        },
        "tags": [],
        "id": "f0e28af5"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0aac607",
      "metadata": {
        "papermill": {
          "duration": 0.002997,
          "end_time": "2025-10-22T09:44:36.147507",
          "exception": false,
          "start_time": "2025-10-22T09:44:36.144510",
          "status": "completed"
        },
        "tags": [],
        "id": "a0aac607"
      },
      "source": [
        "# Installing and Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# 1. INSTALL AND UPGRADE LIBRARIES (IMPORTANT!)\n",
        "# ====================================================\n",
        "!pip install -q --upgrade \\\n",
        "    transformers \\\n",
        "    tokenizers \\\n",
        "    datasets \\\n",
        "    evaluate \\\n",
        "    accelerate \\\n",
        "    torchmetrics\n"
      ],
      "metadata": {
        "id": "Q_ayyB0X60-S"
      },
      "id": "Q_ayyB0X60-S",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import re\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "# ====================================================\n",
        "# CONFIGURATION\n",
        "# ====================================================\n",
        "# Path to your fine-tuned model directory (created by the training script)\n",
        "SAVED_MODEL_PATH = \"/content/toxic_output/best_model\"\n",
        "\n",
        "# Paths to test data (adjust if your environment is different)\n",
        "TEST_CSV_PATH = \"/content/test.csv.zip\"\n",
        "TEST_LABELS_CSV_PATH = \"/content/test_labels.csv.zip\"\n",
        "SUBMISSION_PATH = \"submission.csv\"\n",
        "\n",
        "# Model and training parameters (should match training)\n",
        "MAX_LEN = 256\n",
        "BATCH_SIZE = 32  # Can be larger for inference\n",
        "LABELS = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
        "\n",
        "# Setup device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "\n",
        "# ====================================================\n",
        "# DATA LOADING & PRE-PROCESSING\n",
        "# ====================================================\n",
        "# Load test data\n",
        "test_df = pd.read_csv(TEST_CSV_PATH)\n",
        "test_labels_df = pd.read_csv(TEST_LABELS_CSV_PATH)\n",
        "\n",
        "# Use the exact same cleaning function from your training script\n",
        "def clean_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    url_pattern = r\"http\\S+|www\\.\\S+\"\n",
        "    html_pattern = r\"<.*?>\"\n",
        "    emoji_pattern = r\"[\\U00010000-\\U0010ffff]\"\n",
        "    non_ascii_pattern = r\"[^\\x00-\\x7F]+\"\n",
        "    multi_space_pattern = r\"\\s+\"\n",
        "\n",
        "    text = text.lower()\n",
        "    text = re.sub(url_pattern, \" \", text)\n",
        "    text = re.sub(html_pattern, \" \", text)\n",
        "    text = re.sub(emoji_pattern, \" \", text)\n",
        "    text = re.sub(non_ascii_pattern, \" \", text)\n",
        "    text = re.sub(multi_space_pattern, \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "# Apply cleaning\n",
        "test_df[\"comment\"] = test_df[\"comment_text\"].apply(clean_text)\n",
        "\n",
        "\n",
        "# ====================================================\n",
        "# LOAD MODEL & TOKENIZER\n",
        "# ====================================================\n",
        "print(f\"Loading model and tokenizer from: {SAVED_MODEL_PATH}\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(SAVED_MODEL_PATH)\n",
        "tokenizer = AutoTokenizer.from_pretrained(SAVED_MODEL_PATH)\n",
        "\n",
        "# Move model to the appropriate device\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "\n",
        "# ====================================================\n",
        "# DATASET & DATALOADER\n",
        "# ====================================================\n",
        "class ToxicDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, max_len, is_test=False):\n",
        "        self.texts = df[\"comment\"].tolist()\n",
        "        self.is_test = is_test\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=self.max_len,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        item = {k: v.squeeze(0) for k, v in encoding.items()}\n",
        "        return item\n",
        "\n",
        "# Create dataset and dataloader\n",
        "test_dataset = ToxicDataset(test_df, tokenizer, max_len=MAX_LEN, is_test=True)\n",
        "data_collator = DataCollatorWithPadding(tokenizer)\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    collate_fn=data_collator,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "\n",
        "# ====================================================\n",
        "# INFERENCE LOOP\n",
        "# ====================================================\n",
        "all_preds = []\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader, desc=\"Running Predictions\"):\n",
        "        # Move batch to device\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        logits = outputs.logits\n",
        "        probabilities = torch.sigmoid(logits)\n",
        "        all_preds.append(probabilities.cpu().numpy())\n",
        "\n",
        "# Concatenate all predictions into a single numpy array\n",
        "test_preds = np.concatenate(all_preds, axis=0)\n",
        "\n",
        "\n",
        "# ====================================================\n",
        "# CREATE SUBMISSION FILE\n",
        "# ====================================================\n",
        "submission_df = pd.DataFrame(test_preds, columns=LABELS)\n",
        "submission_df.insert(0, 'id', test_df['id'])\n",
        "submission_df.to_csv(SUBMISSION_PATH, index=False)\n",
        "print(f\"\\n✅ '{SUBMISSION_PATH}' has been created successfully!\")\n",
        "print(\"Submission file head:\")\n",
        "print(submission_df.head())\n",
        "\n",
        "\n",
        "# ====================================================\n",
        "# COMPREHENSIVE EVALUATION\n",
        "# ====================================================\n",
        "# Merge predictions with the true labels\n",
        "eval_df = pd.merge(submission_df, test_labels_df, on='id')\n",
        "\n",
        "# Filter out rows that are not used for scoring (where true labels are -1)\n",
        "score_df = eval_df[eval_df['toxic_y'] != -1].copy()\n",
        "\n",
        "print(f\"\\nEvaluating on {len(score_df)} scored test samples...\")\n",
        "\n",
        "# --- 1. AUC Score (Competition Metric) ---\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"1. ROC AUC Score (Primary Competition Metric)\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "test_aucs = []\n",
        "print(\"Per-class AUC on the test set:\")\n",
        "for label in LABELS:\n",
        "    true_labels = score_df[label + '_y']\n",
        "    pred_probs = score_df[label + '_x']\n",
        "    auc_score = roc_auc_score(true_labels, pred_probs)\n",
        "    test_aucs.append(auc_score)\n",
        "    print(f\"  {label:15s}: {auc_score:.4f}\")\n",
        "\n",
        "macro_auc = np.mean(test_aucs)\n",
        "print(f\"\\n----------------------------------------\")\n",
        "print(f\"✅ Final Test Macro AUC: {macro_auc:.4f}\")\n",
        "print(f\"----------------------------------------\")\n",
        "\n",
        "\n",
        "# --- 2. F1, Precision, Accuracy (at 0.5 threshold) ---\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"2. F1, Precision, Recall, and Accuracy at threshold=0.5\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "# Define the threshold\n",
        "THRESHOLD = 0.5\n",
        "\n",
        "# Extract true labels and predicted probabilities\n",
        "true_labels_all = score_df[[label + '_y' for label in LABELS]].values\n",
        "pred_probs_all = score_df[[label + '_x' for label in LABELS]].values\n",
        "\n",
        "# Convert probabilities to binary predictions\n",
        "pred_binary_all = (pred_probs_all >= THRESHOLD).astype(int)\n",
        "\n",
        "# Exact Match Ratio (Subset Accuracy) - very strict\n",
        "exact_match_ratio = accuracy_score(true_labels_all, pred_binary_all)\n",
        "print(f\"Exact Match Ratio (Subset Accuracy): {exact_match_ratio:.4f}\\n\")\n",
        "\n",
        "# Micro-averaged metrics (good for overall performance)\n",
        "micro_f1 = f1_score(true_labels_all, pred_binary_all, average='micro', zero_division=0)\n",
        "print(f\"Micro-Averaged F1-Score:  {micro_f1:.4f}\")\n",
        "\n",
        "# Per-Class Report (most detailed view)\n",
        "print(\"\\n--- Per-Class Classification Report ---\")\n",
        "report = classification_report(true_labels_all, pred_binary_all, target_names=LABELS, zero_division=0)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "35951713e9c54334b0e596ab667096da",
            "d9f27e294b9a4bebbd04e6646bdab9dd",
            "0ae103f646284a13b1b5482c19c75a1c",
            "234f4d1f0a504bcdbb31c823bcd110f7",
            "b2e7e0b57adf4b73aa4a5f1ee8d41b76",
            "6f2317341c574be699c26b71b39594fa",
            "52732a2eb4574445a5d7264d70eb218f",
            "b6c5409492d6459cadb524a942167714",
            "aef966d2d3f4466aaf3459ec5ca5ff10",
            "473fbae455114e919c133dc7c4fc5f5b",
            "b80900d308064a28b42f2a50a657635a"
          ]
        },
        "id": "xdMxx7-KW31q",
        "outputId": "d6339b64-dcb8-418f-86fa-66e938d1a0a9"
      },
      "id": "xdMxx7-KW31q",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Loading model and tokenizer from: /content/toxic_output/best_model\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Running Predictions:   0%|          | 0/4787 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35951713e9c54334b0e596ab667096da"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ 'submission.csv' has been created successfully!\n",
            "Submission file head:\n",
            "                 id     toxic  severe_toxic   obscene        threat    insult  \\\n",
            "0  00001cee341fdb12  0.996740      0.531942  0.966470  3.095033e-02  0.953445   \n",
            "1  0000247867823ef7  0.000306      0.000003  0.000040  1.056949e-06  0.000020   \n",
            "2  00013b17ad220c46  0.000289      0.000003  0.000037  1.291673e-06  0.000019   \n",
            "3  00017563c3f7919a  0.000256      0.000004  0.000042  1.541029e-06  0.000020   \n",
            "4  00017695ad8997eb  0.000438      0.000002  0.000039  9.042737e-07  0.000020   \n",
            "\n",
            "   identity_hate  \n",
            "0       0.620848  \n",
            "1       0.000013  \n",
            "2       0.000015  \n",
            "3       0.000018  \n",
            "4       0.000011  \n",
            "\n",
            "Evaluating on 63978 scored test samples...\n",
            "\n",
            "============================================================\n",
            "1. ROC AUC Score (Primary Competition Metric)\n",
            "============================================================\n",
            "Per-class AUC on the test set:\n",
            "  toxic          : 0.9702\n",
            "  severe_toxic   : 0.9897\n",
            "  obscene        : 0.9808\n",
            "  threat         : 0.9927\n",
            "  insult         : 0.9762\n",
            "  identity_hate  : 0.9866\n",
            "\n",
            "----------------------------------------\n",
            "✅ Final Test Macro AUC: 0.9827\n",
            "----------------------------------------\n",
            "\n",
            "============================================================\n",
            "2. F1, Precision, Recall, and Accuracy at threshold=0.5\n",
            "============================================================\n",
            "Exact Match Ratio (Subset Accuracy): 0.8719\n",
            "\n",
            "Micro-Averaged F1-Score:  0.6666\n",
            "\n",
            "--- Per-Class Classification Report ---\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        toxic       0.54      0.90      0.68      6090\n",
            " severe_toxic       0.35      0.51      0.42       367\n",
            "      obscene       0.65      0.78      0.71      3691\n",
            "       threat       0.43      0.72      0.54       211\n",
            "       insult       0.58      0.76      0.66      3427\n",
            "identity_hate       0.52      0.68      0.59       712\n",
            "\n",
            "    micro avg       0.56      0.81      0.67     14498\n",
            "    macro avg       0.51      0.73      0.60     14498\n",
            " weighted avg       0.57      0.81      0.67     14498\n",
            "  samples avg       0.07      0.08      0.07     14498\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "databundleVersionId": 44219,
          "sourceId": 8076,
          "sourceType": "competition"
        },
        {
          "isSourceIdPinned": true,
          "modelId": 229582,
          "modelInstanceId": 207879,
          "sourceId": 243356,
          "sourceType": "modelInstanceVersion"
        }
      ],
      "dockerImageVersionId": 31154,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 20792.486125,
      "end_time": "2025-10-22T15:31:04.003041",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-10-22T09:44:31.516916",
      "version": "2.6.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "35951713e9c54334b0e596ab667096da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d9f27e294b9a4bebbd04e6646bdab9dd",
              "IPY_MODEL_0ae103f646284a13b1b5482c19c75a1c",
              "IPY_MODEL_234f4d1f0a504bcdbb31c823bcd110f7"
            ],
            "layout": "IPY_MODEL_b2e7e0b57adf4b73aa4a5f1ee8d41b76"
          }
        },
        "d9f27e294b9a4bebbd04e6646bdab9dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f2317341c574be699c26b71b39594fa",
            "placeholder": "​",
            "style": "IPY_MODEL_52732a2eb4574445a5d7264d70eb218f",
            "value": "Running Predictions: 100%"
          }
        },
        "0ae103f646284a13b1b5482c19c75a1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6c5409492d6459cadb524a942167714",
            "max": 4787,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aef966d2d3f4466aaf3459ec5ca5ff10",
            "value": 4787
          }
        },
        "234f4d1f0a504bcdbb31c823bcd110f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_473fbae455114e919c133dc7c4fc5f5b",
            "placeholder": "​",
            "style": "IPY_MODEL_b80900d308064a28b42f2a50a657635a",
            "value": " 4787/4787 [46:46&lt;00:00,  2.00it/s]"
          }
        },
        "b2e7e0b57adf4b73aa4a5f1ee8d41b76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f2317341c574be699c26b71b39594fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52732a2eb4574445a5d7264d70eb218f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6c5409492d6459cadb524a942167714": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aef966d2d3f4466aaf3459ec5ca5ff10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "473fbae455114e919c133dc7c4fc5f5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b80900d308064a28b42f2a50a657635a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}