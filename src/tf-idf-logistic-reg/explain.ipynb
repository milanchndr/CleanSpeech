{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "562c32ac",
   "metadata": {},
   "source": [
    "## 1. Load pipeline & metadata\n",
    "We’ll load:\n",
    "- `models/baseline_pipeline.joblib` (TF-IDF + One-vs-Rest Logistic Regression)\n",
    "- `models/baseline_meta.json` (has `label_cols`)\n",
    "\n",
    "If the `models/` folder is elsewhere, adjust the path below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12a7601e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pipeline steps: ['tfidf', 'clf']\n",
      "Labels: ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json, joblib\n",
    "\n",
    "# Primary location (as previously saved)\n",
    "MODELS_DIR = Path(\"models\")\n",
    "\n",
    "# Fallbacks if you moved files (uncomment/adjust if needed)\n",
    "if not (MODELS_DIR / \"baseline_pipeline.joblib\").exists():\n",
    "    # Example fallback locations you can try:\n",
    "    # MODELS_DIR = Path.cwd().parent / \"ui\" / \"models\"\n",
    "    # MODELS_DIR = Path.cwd().parent / \"models\"\n",
    "    pass\n",
    "\n",
    "PIPE_PATH = MODELS_DIR / \"baseline_pipeline.joblib\"\n",
    "META_PATH = MODELS_DIR / \"baseline_meta.json\"\n",
    "\n",
    "assert PIPE_PATH.exists(), f\"Pipeline not found at {PIPE_PATH}\"\n",
    "assert META_PATH.exists(), f\"Metadata not found at {META_PATH}\"\n",
    "\n",
    "pipe = joblib.load(PIPE_PATH)\n",
    "\n",
    "with open(META_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    meta = json.load(f)\n",
    "\n",
    "# Labels key per your earlier save format\n",
    "LABELS = meta.get(\"label_cols\")\n",
    "assert isinstance(LABELS, list) and len(LABELS) > 0, \"meta['label_cols'] missing or empty.\"\n",
    "\n",
    "print(\"Loaded pipeline steps:\", [name for name, _ in getattr(pipe, \"steps\", [])])\n",
    "print(\"Labels:\", LABELS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f3eadf",
   "metadata": {},
   "source": [
    "## 2. Extract vectorizer and per-label models\n",
    "From the pipeline:\n",
    "- `tfidf = pipe.named_steps[\"tfidf\"]`\n",
    "- `ovr = pipe.named_steps[\"clf\"]` → `ovr.estimators_` is a list of classifiers, one per label.\n",
    "\n",
    "We’ll map `LABELS[i] → ovr.estimators_[i]` and build a `models_dict`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b4416bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer: TfidfVectorizer\n",
      "Per-label models: {'toxic': 'LogisticRegression', 'severe_toxic': 'LogisticRegression', 'obscene': 'LogisticRegression'} ... total: 6\n"
     ]
    }
   ],
   "source": [
    "# Get the TF-IDF vectorizer\n",
    "assert \"tfidf\" in pipe.named_steps, \"Pipeline has no 'tfidf' step.\"\n",
    "vectorizer = pipe.named_steps[\"tfidf\"]\n",
    "\n",
    "# Get the One-vs-Rest classifier and its per-label estimators\n",
    "assert \"clf\" in pipe.named_steps, \"Pipeline has no 'clf' step (expected OneVsRestClassifier).\"\n",
    "ovr = pipe.named_steps[\"clf\"]\n",
    "\n",
    "# Ensure fitted\n",
    "assert hasattr(ovr, \"estimators_\"), \"ovr.estimators_ not found — was the pipeline fitted?\"\n",
    "\n",
    "estimators = ovr.estimators_\n",
    "assert len(estimators) == len(LABELS), f\"Estimator count {len(estimators)} != labels {len(LABELS)}.\"\n",
    "\n",
    "# Build label → model dict\n",
    "models = {lbl: est for lbl, est in zip(LABELS, estimators)}\n",
    "\n",
    "# Quick sanity print\n",
    "print(\"Vectorizer:\", type(vectorizer).__name__)\n",
    "print(\"Per-label models:\", {k: type(v).__name__ for k, v in list(models.items())[:3]}, \"... total:\", len(models))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8e34bf",
   "metadata": {},
   "source": [
    "## 3. Single-label linear explainer\n",
    "For a chosen `label`, we compute:\n",
    "- `X = vectorizer.transform([text])`\n",
    "- `z = w·X + b` (logit) from the per-label estimator\n",
    "- `p = 1 / (1 + exp(-z))`\n",
    "- token-level contributions: `contrib[token] = w[token] × X[token]`\n",
    "\n",
    "We’ll aggregate duplicate tokens (e.g., bi-grams overlapping with uni-grams) and return:\n",
    "- `prob`, `logit`, `bias`, and a dict `token_contributions`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "990024dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def _logit_from_estimator(X, est):\n",
    "    \"\"\"Return scalar logit z for binary estimator on a single-row X.\"\"\"\n",
    "    if hasattr(est, \"decision_function\"):\n",
    "        z = est.decision_function(X)\n",
    "        # shape could be (1,) or (1,1)\n",
    "        z = np.asarray(z).ravel()[0]\n",
    "        return float(z)\n",
    "    if hasattr(est, \"predict_proba\"):\n",
    "        p = est.predict_proba(X)[:, 1][0]\n",
    "        p = float(np.clip(p, 1e-9, 1 - 1e-9))\n",
    "        return float(np.log(p / (1 - p)))\n",
    "    raise ValueError(\"Estimator lacks decision_function/predict_proba\")\n",
    "\n",
    "def _weights_intercept(est):\n",
    "    \"\"\"Get (w, b) on linear models; unwrap common wrappers if needed.\"\"\"\n",
    "    # Direct\n",
    "    if hasattr(est, \"coef_\"):\n",
    "        w = est.coef_.ravel()\n",
    "        b = float(getattr(est, \"intercept_\", np.array([0.0]))[0])\n",
    "        return w, b\n",
    "    # Try common wrappers\n",
    "    for attr in (\"base_estimator\", \"estimator\", \"classifier\"):\n",
    "        inner = getattr(est, attr, None)\n",
    "        if inner is not None and hasattr(inner, \"coef_\"):\n",
    "            w = inner.coef_.ravel()\n",
    "            b = float(getattr(inner, \"intercept_\", np.array([0.0]))[0])\n",
    "            return w, b\n",
    "    raise ValueError(\"Cannot access linear weights (coef_). Is the base model linear?\")\n",
    "\n",
    "def linear_token_contribs(text: str, label: str, *, vectorizer, models):\n",
    "    \"\"\"\n",
    "    Compute token contributions for a single label.\n",
    "    Returns: dict with prob, logit, bias, token_contributions (dict token->float).\n",
    "    \"\"\"\n",
    "    # Vectorize using the trained vectorizer (same preprocessing/tokenization as training)\n",
    "    X = vectorizer.transform([text])\n",
    "\n",
    "    est = models[label]\n",
    "    z = _logit_from_estimator(X, est)\n",
    "    p = 1.0 / (1.0 + np.exp(-z))\n",
    "    w, b = _weights_intercept(est)\n",
    "\n",
    "    # Active features and their tf-idf values\n",
    "    X_csr = X.tocsr()\n",
    "    idxs = X_csr.indices\n",
    "    vals = X_csr.data\n",
    "\n",
    "    # contributions in logit space\n",
    "    contribs = w[idxs] * vals\n",
    "\n",
    "    # Map feature indices back to tokens\n",
    "    inv_vocab = {j: t for t, j in vectorizer.vocabulary_.items()}\n",
    "    tokens = [inv_vocab[j] for j in idxs]\n",
    "\n",
    "    # Aggregate duplicate tokens\n",
    "    agg = {}\n",
    "    for t, c in zip(tokens, contribs):\n",
    "        agg[t] = agg.get(t, 0.0) + float(c)\n",
    "\n",
    "    return {\n",
    "        \"prob\": float(p),\n",
    "        \"logit\": float(z),\n",
    "        \"bias\": float(b),\n",
    "        \"token_contributions\": agg,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0cceac",
   "metadata": {},
   "source": [
    "## 4. Validate on a sample\n",
    "We’ll run the explainer on one short comment for a chosen label and inspect the top contributors by absolute value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb645237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'toxic', 'prob': 0.9999, 'logit': 8.8362}\n",
      "Top contributors (logit space):\n",
      "idiot                 +4.2091\n",
      "an idiot              +1.2153\n",
      "worst                 +0.9780\n",
      "you                   +0.8191\n",
      "the worst             +0.7471\n",
      "are an                +0.6704\n",
      "ever                  +0.6434\n",
      "you are               +0.6361\n",
      "are                   +0.3395\n",
      "this is               -0.1512\n",
      "is                    +0.1357\n",
      "the                   -0.1315\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"You are an idiot. This is the worst comment ever.\"\n",
    "focus_label = LABELS[0]  # e.g., \"toxic\" — change if you want\n",
    "\n",
    "exp = linear_token_contribs(sample_text, focus_label, vectorizer=vectorizer, models=models)\n",
    "top = sorted(exp[\"token_contributions\"].items(), key=lambda kv: abs(kv[1]), reverse=True)\n",
    "\n",
    "print({\"label\": focus_label, \"prob\": round(exp[\"prob\"], 4), \"logit\": round(exp[\"logit\"], 4)})\n",
    "print(\"Top contributors (logit space):\")\n",
    "for t, c in top[:12]:\n",
    "    print(f\"{t:20s}  {c:+.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dbbc22",
   "metadata": {},
   "source": [
    "## 5. What-if analysis\n",
    "We’ll remove or replace a token (case-insensitive, whole-word) and see how the probability for the focused label changes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "def9ad5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def what_if_remove(text: str, token: str, label: str, *, vectorizer, models):\n",
    "    pat = rf\"\\b{re.escape(token)}\\b\"\n",
    "    edited = re.sub(pat, \" \", text, flags=re.IGNORECASE)\n",
    "    before = linear_token_contribs(text,   label, vectorizer=vectorizer, models=models)[\"prob\"]\n",
    "    after  = linear_token_contribs(edited, label, vectorizer=vectorizer, models=models)[\"prob\"]\n",
    "    return {\n",
    "        \"action\": \"remove\",\n",
    "        \"token\": token,\n",
    "        \"before\": float(before),\n",
    "        \"after\":  float(after),\n",
    "        \"delta\":  float(after - before),\n",
    "        \"edited_text\": edited,\n",
    "    }\n",
    "\n",
    "def what_if_replace(text: str, token: str, replacement: str, label: str, *, vectorizer, models):\n",
    "    pat = rf\"\\b{re.escape(token)}\\b\"\n",
    "    edited = re.sub(pat, replacement, text, flags=re.IGNORECASE)\n",
    "    before = linear_token_contribs(text,   label, vectorizer=vectorizer, models=models)[\"prob\"]\n",
    "    after  = linear_token_contribs(edited, label, vectorizer=vectorizer, models=models)[\"prob\"]\n",
    "    return {\n",
    "        \"action\": \"replace\",\n",
    "        \"token\": token,\n",
    "        \"replacement\": replacement,\n",
    "        \"before\": float(before),\n",
    "        \"after\":  float(after),\n",
    "        \"delta\":  float(after - before),\n",
    "        \"edited_text\": edited,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69b37985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'action': 'remove',\n",
       " 'token': 'idiot',\n",
       " 'before': 0.9998546402762276,\n",
       " 'after': 0.981243896211523,\n",
       " 'delta': -0.018610744064704643,\n",
       " 'edited_text': 'You are an  . This is the worst comment ever.'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "what_if_remove(sample_text, \"idiot\", focus_label, vectorizer=vectorizer, models=models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1efef3",
   "metadata": {},
   "source": [
    "## 6. Explain all labels + compact JSON\n",
    "We’ll compute:\n",
    "- Per-label probabilities for the text.\n",
    "- One focused label’s token contributions.\n",
    "- A compact payload suitable for the UI to download or display.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb984d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_all_labels(text: str, *, vectorizer, models, labels):\n",
    "    probs = {}\n",
    "    for lbl in labels:\n",
    "        p = linear_token_contribs(text, lbl, vectorizer=vectorizer, models=models)[\"prob\"]\n",
    "        probs[lbl] = float(p)\n",
    "    return probs\n",
    "\n",
    "def build_explanation_payload(text: str, label: str, *, vectorizer, models, labels, threshold: float = 0.5):\n",
    "    exp = linear_token_contribs(text, label, vectorizer=vectorizer, models=models)\n",
    "    payload = {\n",
    "        \"text\": text,\n",
    "        \"label\": label,\n",
    "        \"threshold\": float(threshold),\n",
    "        \"probabilities\": explain_all_labels(text, vectorizer=vectorizer, models=models, labels=labels),\n",
    "        \"explanation\": {\n",
    "            \"bias\": float(exp[\"bias\"]),\n",
    "            \"logit\": float(exp[\"logit\"]),\n",
    "            \"token_contributions\": exp[\"token_contributions\"],  # dict token -> logit contribution\n",
    "        },\n",
    "        \"predicted\": bool(exp[\"prob\"] >= threshold),\n",
    "    }\n",
    "    return payload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f6a3fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"text\": \"You are an idiot. This is the worst comment ever.\",\n",
      "  \"label\": \"toxic\",\n",
      "  \"threshold\": 0.5,\n",
      "  \"probabilities\": {\n",
      "    \"toxic\": 0.9998546402762276,\n",
      "    \"severe_toxic\": 0.11633880980412105,\n",
      "    \"obscene\": 0.899354640984587,\n",
      "    \"threat\": 0.013199508069555322,\n",
      "    \"insult\": 0.9997739805767635,\n",
      "    \"identity_hate\": 0.24543510433230759\n",
      "  },\n",
      "  \"explanation\": {\n",
      "    \"bias\": -1.4071821295020228,\n",
      "    \"logit\": 8.836153663888966,\n",
      "    \"token_contributions\": {\n",
      "      \"an\": 0.04634766088388386,\n",
      "      \"an idiot\": 1.2153161457573238,\n",
      "      \"are\": 0.33954640046836143,\n",
      "      \"are an\": 0.6704142675447535,\n",
      "      \"comment\": 0.027014049151402125,\n",
      "      \"ever\": 0.6434071197386951,\n",
      "      \"idiot\": 4.209143713050065,\n",
      "      \"idiot this\": 0.026189527321537114,\n",
      "      \"is\": 0.1356997950192003,\n",
      "      \"is the\": ...\n"
     ]
    }
   ],
   "source": [
    "payload = build_explanation_payload(sample_text, focus_label, vectorizer=vectorizer, models=models, labels=LABELS, threshold=0.5)\n",
    "# Peek (truncate print)\n",
    "import json\n",
    "print(json.dumps(payload, indent=2)[:800], \"...\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
