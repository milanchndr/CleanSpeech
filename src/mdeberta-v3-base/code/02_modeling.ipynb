{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "196655a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.13.7 (tags/v3.13.7:bcee1c3, Aug 14 2025, 14:15:11) [MSC v.1944 64 bit (AMD64)]\n",
      "CUDA available: False\n",
      "Running on CPU\n",
      "../../data/train_data.csv\n",
      "microsoft/mdeberta-v3-base\n",
      "‚úÖ Config loaded and random seed set to: 42\n",
      "üìÇ Model directory: ../models/best\n",
      "üìÇ Reports directory: ../reports\n",
      "‚úÖ Folder setup complete.\n",
      "‚úÖ Found: ..\\..\\data\\train_data.csv\n",
      "‚úÖ Found: ..\\..\\data\\test_data.csv\n",
      "\n",
      "All required data files are present and accessible.\n",
      "‚úÖ Configuration snapshot saved at:\n",
      "../reports\\config_snapshot.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alaud\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: microsoft/mdeberta-v3-base\n",
      "Max length: 256\n",
      "Device: CPU\n"
     ]
    }
   ],
   "source": [
    "# Cell 1 ‚Äî Load config and core libs\n",
    "%run ./00_config.ipynb\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "print(\"Model:\", cfg.train.model_name)\n",
    "print(\"Max length:\", cfg.train.max_len)\n",
    "print(\"Device:\", \"CUDA\" if torch.cuda.is_available() else \"CPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc3d866d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# 1Ô∏è‚É£ Load tokenizer\n",
    "def get_tokenizer(cfg=None):\n",
    "    cfg = cfg or default_cfg()\n",
    "    return AutoTokenizer.from_pretrained(cfg.train.model_name)\n",
    "\n",
    "# 2Ô∏è‚É£ Load model (multi-label classification)\n",
    "def get_model(cfg=None, num_labels=6):\n",
    "    cfg = cfg or default_cfg()\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        cfg.train.model_name,\n",
    "        num_labels=num_labels,\n",
    "        problem_type=\"multi_label_classification\"\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# 3Ô∏è‚É£ Define loss function\n",
    "def get_loss(cfg, label_freq: np.ndarray):\n",
    "    \"\"\"\n",
    "    Weighted BCEWithLogitsLoss if cfg.train.class_weighting == 'auto',\n",
    "    else plain BCEWithLogitsLoss.\n",
    "    \"\"\"\n",
    "    if cfg.train.class_weighting == \"auto\":\n",
    "        weights = 1.0 / (label_freq + 1e-6)\n",
    "        weights = weights / weights.sum() * len(label_freq)\n",
    "        weights = torch.tensor(weights, dtype=torch.float)\n",
    "    else:\n",
    "        weights = torch.ones(len(label_freq), dtype=torch.float)\n",
    "\n",
    "    def loss_fn(logits, targets):\n",
    "        return nn.functional.binary_cross_entropy_with_logits(\n",
    "            logits, targets, weight=weights.to(logits.device)\n",
    "        )\n",
    "    return loss_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f995415d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Hugging Face cache at: c:\\Users\\alaud\\OneDrive\\Desktop\\iitm-ds-lab-proj\\CleanSpeech\\.cache\\huggingface\\models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "c:\\Users\\alaud\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Model initialized: microsoft/mdeberta-v3-base\n",
      "Device: cpu\n",
      "Total parameters: 278,813,958\n",
      "Trainable parameters: 278,813,958\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 ‚Äî Enable local Hugging Face cache + load model/tokenizer\n",
    "import os, torch\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1Ô∏è‚É£ Set a local cache path (once)\n",
    "# This will be inside your project folder so you can reuse the model.\n",
    "# ------------------------------------------------------------------\n",
    "os.environ[\"HF_HOME\"] = os.path.abspath(\"../../../.cache/huggingface\")\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = os.path.join(os.environ[\"HF_HOME\"], \"models\")\n",
    "\n",
    "print(\"Using Hugging Face cache at:\", os.environ[\"TRANSFORMERS_CACHE\"])\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2Ô∏è‚É£ (Optional) install Xet optimization if you want faster downloads\n",
    "# ------------------------------------------------------------------\n",
    "# Uncomment if you want to actually install it:\n",
    "!pip install -q \"huggingface_hub[hf_xet]\"\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3Ô∏è‚É£ Load tokenizer and model\n",
    "# ------------------------------------------------------------------\n",
    "tokenizer = get_tokenizer(cfg)\n",
    "model = get_model(cfg, num_labels=len(cfg.labels))\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4Ô∏è‚É£ Show summary info\n",
    "# ------------------------------------------------------------------\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\n‚úÖ Model initialized: {cfg.train.model_name}\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65a7a68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using fallback: label frequencies computed from raw train CSV.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "toxic            0.095844\n",
       "severe_toxic     0.009996\n",
       "obscene          0.052948\n",
       "threat           0.002996\n",
       "insult           0.049364\n",
       "identity_hate    0.008805\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Loss function ready (weighted BCE with logits if class_weighting='auto').\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 ‚Äî Compute label frequencies and instantiate weighted loss\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def _label_freq_from_train_df(df, labels):\n",
    "    # frequency = (#positives per label) / (#rows)\n",
    "    return (df[list(labels)].sum(axis=0) / len(df))\n",
    "\n",
    "def _label_freq_fallback(cfg, labels):\n",
    "    # Fallback: compute directly from raw CSV if train_df isn't in this kernel\n",
    "    train_raw = pd.read_csv(cfg.paths.raw_train)\n",
    "    # ensure the label columns exist\n",
    "    present = [c for c in labels if c in train_raw.columns]\n",
    "    if not present:\n",
    "        raise ValueError(f\"No label columns from {list(labels)} found in {cfg.paths.raw_train}.\")\n",
    "    return (train_raw[present].sum(axis=0) / len(train_raw)).reindex(labels).fillna(0.0)\n",
    "\n",
    "# Try to use train_df from 01_data; else fallback\n",
    "try:\n",
    "    _ = train_df  # raises NameError if not present\n",
    "    label_freq = _label_freq_from_train_df(train_df, cfg.labels)\n",
    "    print(\"Using label frequencies from train_df (01_data).\")\n",
    "except NameError:\n",
    "    label_freq = _label_freq_fallback(cfg, cfg.labels)\n",
    "    print(\"Using fallback: label frequencies computed from raw train CSV.\")\n",
    "\n",
    "display(label_freq)\n",
    "\n",
    "# Build loss\n",
    "loss_fn = get_loss(cfg, label_freq.values)\n",
    "print(\"\\n‚úÖ Loss function ready (weighted BCE with logits if class_weighting='auto').\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
